{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9c7e77d2a2f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import flags\n",
    "import time \n",
    "import logging\n",
    "import os\n",
    "from cleverhans.attacks import CarliniWagnerL2\n",
    "from cleverhans.utils import pair_visual, grid_visual, AccuracyReport\n",
    "from cleverhans.utils import set_log_level\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils_tf import model_train, model_eval, tf_model_load\n",
    "from cleverhans_tutorials.tutorial_models import make_basic_cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def mnist_cw(train_start=0, train_end=60000, test_start=0,\n",
    "                      test_end=10000, nb_epochs=6,\n",
    "                      batch_size=128, nb_classes=10, source_samples=10,\n",
    "                      learning_rate=0.001, attack_iterations=10,\n",
    "                      model_path=os.path.join(\"models\", \"mnist\"),\n",
    "                      targeted=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    reproducing C & W attack on MNIST data set.\n",
    "    :param train_start: index of first training set example\n",
    "    :param train_end: index of last training set example\n",
    "    :param test_start: index of first test set example\n",
    "    :param test_end: index of last test set example\n",
    "    :param nb_epochs: number of epochs to train model\n",
    "    :param batch_size: size of training batches\n",
    "    :param nb_classes: number of output classes\n",
    "    :param source_samples: number of test inputs to attack\n",
    "    :param learning_rate: learning rate for training\n",
    "    :param model_path: path to the model file\n",
    "    :param targeted: should we run a targeted attack? or untargeted?\n",
    "    :return: an AccuracyReport object\n",
    "    \"\"\"\n",
    "    # Object used to keep track of (and return) key accuracies\n",
    "    report = AccuracyReport()\n",
    "\n",
    "    # Set TF random seed to improve reproducibility\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    # Create TF session\n",
    "    sess = tf.Session()\n",
    "    print(\"Created TensorFlow session.\")\n",
    "\n",
    "    set_log_level(logging.DEBUG)\n",
    "\n",
    "    # Get MNIST test data\n",
    "    X_train, Y_train, X_test, Y_test = data_mnist(train_start=train_start,\n",
    "                                                  train_end=train_end,\n",
    "                                                  test_start=test_start,\n",
    "                                                  test_end=test_end)\n",
    "    # MNIST-specific dimensions\n",
    "    img_rows = 28\n",
    "    img_cols = 28\n",
    "    channels = 1\n",
    "    # Define input TF placeholder\n",
    "    x = tf.placeholder(tf.float32, shape=(None, img_rows, img_cols, channels))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, nb_classes))\n",
    "\n",
    "    # Define TF model graph\n",
    "    model = make_basic_cnn()\n",
    "    preds = model(x)\n",
    "    print(\"Defined TensorFlow model graph.\")\n",
    "\n",
    "    # Train an MNIST model\n",
    "    train_params = {\n",
    "        'nb_epochs': nb_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate,\n",
    "        'train_dir': os.path.join(*os.path.split(model_path)[:-1]),\n",
    "        'filename': os.path.split(model_path)[-1]\n",
    "    }\n",
    "\n",
    "    rng = np.random.RandomState([2017, 12, 10])\n",
    "    \n",
    "    model_train(sess, x, y, preds, X_train, Y_train, args=train_params,\n",
    "                save=os.path.exists(\"models\"), rng=rng)\n",
    "    start = time.time()\n",
    "    \n",
    "    \n",
    "    # Instantiating C & W attack\n",
    "    cw = CarliniWagnerL2(model, back='tf', sess=sess)\n",
    "\n",
    "    if targeted:\n",
    "        adv_inputs = np.array(\n",
    "            [[instance] * nb_classes for\n",
    "             instance in X_test[:source_samples]], dtype=np.float32)\n",
    "        one_hot = np.zeros((nb_classes, nb_classes))\n",
    "        one_hot[np.arange(nb_classes), np.arange(nb_classes)] = 1\n",
    "\n",
    "        adv_inputs = adv_inputs.reshape(\n",
    "            (source_samples * nb_classes, img_rows, img_cols, 1))\n",
    "        adv_ys = np.array([one_hot] * source_samples,\n",
    "                          dtype=np.float32).reshape((source_samples *\n",
    "                                                     nb_classes, nb_classes))\n",
    "        yname = \"y_target\"\n",
    "    else:\n",
    "        adv_inputs = X_test[:source_samples]\n",
    "\n",
    "        adv_ys = None\n",
    "        yname = \"y\"\n",
    "\n",
    "    cw_params = {'binary_search_steps': 1,\n",
    "                 yname: adv_ys,\n",
    "                 'max_iterations': attack_iterations,\n",
    "                 'learning_rate': 0.1,\n",
    "                 'batch_size': source_samples * nb_classes if\n",
    "                 targeted else source_samples,\n",
    "                 'initial_const': 10}\n",
    "\n",
    "    adv = cw.generate_np(adv_inputs,\n",
    "                         **cw_params)\n",
    "\n",
    "    eval_params = {'batch_size': np.minimum(nb_classes, source_samples)}\n",
    "    if targeted:\n",
    "        adv_accuracy = model_eval(\n",
    "            sess, x, y, preds, adv, adv_ys, args=eval_params)\n",
    "    else:\n",
    "        adv_accuracy = 1 - \\\n",
    "            model_eval(sess, x, y, preds, adv, Y_test[\n",
    "                       :source_samples], args=eval_params)\n",
    "\n",
    "    end = = time.time()\n",
    "    print('--------------------------------------')\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    print('Acc on adversarial examples. {0:.4f}'.format(adv_accuracy))\n",
    "    report.clean_train_adv_eval = 1. - adv_accuracy\n",
    "\n",
    "    percent_perturbed = np.mean(np.sum((adv - adv_inputs)**2,\n",
    "                                       axis=(1, 2, 3))**.5)/784\n",
    "    print('Mean perturbations score {0:.4f}'.format(percent_perturbed))\n",
    "    print('took %d seconds'%(end-start))\n",
    "    # Close TF session\n",
    "    sess.close()\n",
    "\n",
    "\n",
    "tf.app.run()\n",
    "try:\n",
    "    modelpath = os.path.join(\"models\", \"mnist\")\n",
    "except:\n",
    "    modelpath = None\n",
    "for nb_epochs in [6,12,18]:\n",
    "    mnist_tutorial_cw(nb_epochs=nb_epochs,\n",
    "                          batch_size=128,\n",
    "                          nb_classes=10,\n",
    "                          source_samples=10,\n",
    "                          learning_rate=0.01,\n",
    "                          attack_iterations=100,\n",
    "                          model_path=modelpath,\n",
    "                          targeted=True)\n",
    "    \n",
    "for attack_iter in [10,50,80,100]:\n",
    "    mnist_tutorial_cw(nb_epochs=nb_epochs,\n",
    "                          batch_size=128,\n",
    "                          nb_classes=10,\n",
    "                          source_samples=10,\n",
    "                          learning_rate=0.01,\n",
    "                          attack_iterations=attack_iter,\n",
    "                          model_path=modelpath,\n",
    "                          targeted=True)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
